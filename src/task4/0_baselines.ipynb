{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Link Prediction Baselines\n",
    "\n",
    "before throwing neural nets at the problem, I try to understand what we're predicting\n",
    "and see how far simple methods go. every ML result needs a baseline to mean anything.\n",
    "\n",
    "link prediction: given a knowledge graph with some edges missing, can we predict them.\n",
    "for each test triplet (h, r, ?), rank all possible tail entities. lower rank is a better prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "from task4_utils import load_triplets, build_mappings, triplets_to_ids, compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 13821 triplets\n",
      "test:  590 triplets\n",
      "\n",
      "train relations (28 types):\n",
      "  grandsonOf: 814\n",
      "  grandmotherOf: 813\n",
      "  grandfatherOf: 813\n",
      "  granddaughterOf: 812\n",
      "  motherOf: 733\n",
      "  fatherOf: 733\n",
      "  sisterOf: 636\n",
      "  daughterOf: 628\n",
      "  greatGrandsonOf: 624\n",
      "  greatGrandmotherOf: 617\n",
      "  greatGrandfatherOf: 617\n",
      "  greatGranddaughterOf: 610\n",
      "  sonOf: 600\n",
      "  brotherOf: 570\n",
      "  auntOf: 556\n",
      "  nephewOf: 514\n",
      "  nieceOf: 496\n",
      "  uncleOf: 454\n",
      "  girlCousinOf: 445\n",
      "  boyCousinOf: 391\n",
      "  greatAuntOf: 312\n",
      "  greatUncleOf: 237\n",
      "  boyFirstCousinOnceRemovedOf: 180\n",
      "  secondAuntOf: 175\n",
      "  secondUncleOf: 158\n",
      "  girlFirstCousinOnceRemovedOf: 153\n",
      "  boySecondCousinOf: 68\n",
      "  girlSecondCousinOf: 62\n",
      "\n",
      "test relations (4 types):\n",
      "  sonOf: 214\n",
      "  daughterOf: 200\n",
      "  motherOf: 88\n",
      "  fatherOf: 88\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = 'data/train.txt'\n",
    "TEST_PATH = 'data/test.txt'\n",
    "\n",
    "train_raw = load_triplets(TRAIN_PATH)\n",
    "test_raw = load_triplets(TEST_PATH)\n",
    "\n",
    "print(f\"train: {len(train_raw)} triplets\")\n",
    "print(f\"test:  {len(test_raw)} triplets\")\n",
    "\n",
    "train_rels = Counter(r for _, r, _ in train_raw)\n",
    "test_rels = Counter(r for _, r, _ in test_raw)\n",
    "\n",
    "print(f\"\\ntrain relations ({len(train_rels)} types):\")\n",
    "for r, c in train_rels.most_common():\n",
    "    print(f\"  {r}: {c}\")\n",
    "\n",
    "print(f\"\\ntest relations ({len(test_rels)} types):\")\n",
    "for r, c in test_rels.most_common():\n",
    "    print(f\"  {r}: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first observation\n",
    "\n",
    "the test set only has 4 relation types: motherOf, fatherOf, sonOf, daughterOf.\n",
    "all parent-child relations. the test is asking if we can recover the core family backbone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities:  1316\n",
      "relations: 28\n",
      "total known triplets: 14411\n"
     ]
    }
   ],
   "source": [
    "# build ID mappings\n",
    "entity2id, relation2id, id2entity, id2relation = build_mappings(train_raw, test_raw)\n",
    "train_ids = triplets_to_ids(train_raw, entity2id, relation2id)\n",
    "test_ids = triplets_to_ids(test_raw, entity2id, relation2id)\n",
    "\n",
    "num_entities = len(entity2id)\n",
    "num_relations = len(relation2id)\n",
    "\n",
    "print(f\"entities:  {num_entities}\")\n",
    "print(f\"relations: {num_relations}\")\n",
    "\n",
    "# all known triples for filtering\n",
    "all_true = set()\n",
    "for row in train_ids:\n",
    "    all_true.add(tuple(row))\n",
    "for row in test_ids:\n",
    "    all_true.add(tuple(row))\n",
    "\n",
    "print(f\"total known triplets: {len(all_true)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline 1: random\n",
    "\n",
    "if we rank entities randomly, what's the expected MRR?\n",
    "with N entities, expected rank ≈ N/2, so MRR ≈ 2/N.\n",
    "this is our absolute floor. anything smart should do better than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num entities: 1316\n",
      "expected rank: 658\n",
      "random MRR: 0.001520\n",
      "random Hits@10: 0.007599\n",
      "\n",
      "so any model with MRR above 0.0015 is learning something\n"
     ]
    }
   ],
   "source": [
    "# analytical random baseline\n",
    "expected_rank = num_entities / 2\n",
    "random_mrr = 1.0 / expected_rank\n",
    "\n",
    "print(f\"num entities: {num_entities}\")\n",
    "print(f\"expected rank: {expected_rank:.0f}\")\n",
    "print(f\"random MRR: {random_mrr:.6f}\")\n",
    "print(f\"random Hits@10: {10/num_entities:.6f}\")\n",
    "\n",
    "print(f\"\\nso any model with MRR above {random_mrr:.4f} is learning something\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline 2: frequency\n",
    "\n",
    "for each (head, relation), rank candidate tails by how often they appear\n",
    "as tails of that relation type in the training set.\n",
    "this captures how some people are more \"central\" and appear in more relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0/590\n",
      "  100/590\n",
      "  200/590\n",
      "  300/590\n",
      "  400/590\n",
      "  500/590\n",
      "\n",
      "Frequency baseline:\n",
      "  mrr: 0.0058\n",
      "  hits@1: 0.0000\n",
      "  hits@3: 0.0000\n",
      "  hits@10: 0.0119\n",
      "  mean_rank: 352.2780\n"
     ]
    }
   ],
   "source": [
    "rel_tail_freq = defaultdict(Counter)\n",
    "for h, r, t in train_ids:\n",
    "    rel_tail_freq[r][t] += 1\n",
    "\n",
    "rel_head_freq = defaultdict(Counter)\n",
    "for h, r, t in train_ids:\n",
    "    rel_head_freq[r][h] += 1\n",
    "\n",
    "# also count general tail frequency\n",
    "tail_freq = Counter()\n",
    "for h, r, t in train_ids:\n",
    "    tail_freq[t] += 1\n",
    "\n",
    "\n",
    "def frequency_rank(h, r, t, all_true_set, num_entities):\n",
    "\n",
    "    freq = rel_tail_freq[r]\n",
    "    target_score = freq.get(t, 0)\n",
    "    \n",
    "    rank = 1\n",
    "    for e in range(num_entities):\n",
    "        if e == t:\n",
    "            continue\n",
    "        if (h, r, e) in all_true_set:\n",
    "            continue\n",
    "        if freq.get(e, 0) > target_score:\n",
    "            rank += 1\n",
    "    return rank\n",
    "\n",
    "\n",
    "freq_ranks = []\n",
    "for h, r, t in test_ids:\n",
    "\n",
    "    rank_t = frequency_rank(h, r, t, all_true, num_entities)\n",
    "    freq_ranks.append(rank_t)\n",
    "    \n",
    "    head_freq = defaultdict(Counter)\n",
    "    \n",
    "\n",
    "\n",
    "def frequency_rank_head(h, r, t, all_true_set, num_entities):\n",
    "\n",
    "    freq = rel_head_freq[r]\n",
    "    target_score = freq.get(h, 0)\n",
    "    rank = 1\n",
    "\n",
    "    for e in range(num_entities):\n",
    "        if e == h:\n",
    "            continue\n",
    "        if (e, r, t) in all_true_set:\n",
    "            continue\n",
    "        if freq.get(e, 0) > target_score:\n",
    "            rank += 1\n",
    "    return rank\n",
    "\n",
    "freq_ranks_all = []\n",
    "\n",
    "for i, (h, r, t) in enumerate(test_ids):\n",
    "\n",
    "    rank_t = frequency_rank(h, r, t, all_true, num_entities)\n",
    "    rank_h = frequency_rank_head(h, r, t, all_true, num_entities)\n",
    "    freq_ranks_all.extend([rank_t, rank_h])\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"  {i}/{len(test_ids)}\")\n",
    "\n",
    "freq_metrics = compute_metrics(np.array(freq_ranks_all, dtype=np.float64))\n",
    "print(f\"\\nFrequency baseline:\")\n",
    "for k, v in freq_metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline 3: rule-based (connecting to task 3)\n",
    "\n",
    "we know from task 3 that family relations follow strict logical rules.\n",
    "the test set only has parent-child relations, so let's use inverse rules:\n",
    "\n",
    "- if motherOf(A, B) is in train , predict daughterOf(B, A) or sonOf(B, A)\n",
    "- if fatherOf(A, B) is in train , predict daughterOf(B, A) or sonOf(B, A)\n",
    "- if sonOf(A, B) is in train , predict motherOf(B, A) or fatherOf(B, A)\n",
    "- if daughterOf(A, B) is in train , predict motherOf(B, A) or fatherOf(B, A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test triplets recoverable by inverse rules: 590/590\n",
      "coverage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_lookup = defaultdict(set)\n",
    "for h, r, t in train_raw:\n",
    "    train_lookup[(h, r)].add(t)\n",
    "\n",
    "\n",
    "INVERSE_MAP = {\n",
    "    'motherOf': ['sonOf', 'daughterOf'],\n",
    "    'fatherOf': ['sonOf', 'daughterOf'],\n",
    "    'sonOf': ['motherOf', 'fatherOf'],\n",
    "    'daughterOf': ['motherOf', 'fatherOf'],\n",
    "}\n",
    "\n",
    "rule_hits = 0\n",
    "rule_total = 0\n",
    "\n",
    "for h, r, t in test_raw:\n",
    "    rule_total += 1\n",
    "    \n",
    "    #  does any inverse of (h, rel, t) exist in training?\n",
    "    # inverse means (t, inverse_rel, h) in train \n",
    "    found = False\n",
    "    if r in INVERSE_MAP:\n",
    "        for inv_r in INVERSE_MAP[r]:\n",
    "            if h in train_lookup.get((t, inv_r), set()):\n",
    "                found = True\n",
    "                break\n",
    "    \n",
    "    if found:\n",
    "        rule_hits += 1\n",
    "\n",
    "print(f\"test triplets recoverable by inverse rules: {rule_hits}/{rule_total}\")\n",
    "print(f\"coverage: {rule_hits/rule_total:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
